{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "predictCounty.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "CsluoFv7Sp2j"
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "tlcuuCFhSp3G"
   },
   "source": [
    "years = range(2000,2020,4)\n",
    "df = pd.read_csv('counties.csv')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PrR6Do9iSp3f",
    "outputId": "8bbff5da-d8f3-4ea1-f2f3-593f064f7644",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    }
   },
   "source": [
    "data = df.drop(columns=['state', 'county'])\n",
    "data = data.dropna(axis=0,how='any')\n",
    "data.describe()"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "              2000D          2000R          2000O         2004D         2004R  \\\ncount  2.875000e+03    2875.000000    2875.000000  2.875000e+03  2.875000e+03   \nmean   1.699424e+04   16533.856000    1352.073391  1.956915e+04  2.028555e+04   \nstd    5.942532e+04   39923.542134    4232.141433  6.769202e+04  4.869764e+04   \nmin    1.400000e+01     106.000000       3.000000  1.200000e+01  6.500000e+01   \n25%    1.751500e+03    2689.000000     109.000000  1.882500e+03  3.124500e+03   \n50%    3.830000e+03    5363.000000     278.000000  4.177000e+03  6.522000e+03   \n75%    9.580500e+03   13166.000000     886.500000  1.078350e+04  1.646800e+04   \nmax    1.710505e+06  871930.000000  112719.000000  1.907736e+06  1.076225e+06   \n\n              2004O         2008D          2008R         2008O         2012D  \\\ncount   2875.000000  2.875000e+03    2875.000000   2875.000000  2.875000e+03   \nmean     508.671652  2.298134e+04   19539.632696    610.991304  2.171365e+04   \nstd     1976.171276  7.944593e+04   45955.629730   1913.652362  7.628626e+04   \nmin        0.000000  8.000000e+00      67.000000      0.000000  5.000000e+00   \n25%       43.000000  1.930500e+03    2956.000000     78.500000  1.662500e+03   \n50%       98.000000  4.493000e+03    6297.000000    182.000000  4.014000e+03   \n75%      302.000000  1.262450e+04   16042.000000    453.500000  1.147700e+04   \nmax    39515.000000  2.295853e+06  956425.000000  65970.000000  2.216903e+06   \n\n               2012R         2012O         2016D          2016R          2016O  \ncount    2875.000000   2875.000000  2.875000e+03    2875.000000    2875.000000  \nmean    19761.090783    886.516522  2.175607e+04   20524.178783    2543.772522  \nstd     45649.528293   3056.034805  8.298175e+04   44262.493478    7726.198627  \nmin        54.000000      1.000000  4.000000e+00      58.000000       3.000000  \n25%      3021.500000     84.000000  1.240000e+03    3346.000000     195.000000  \n50%      6398.000000    195.000000  3.199000e+03    7194.000000     529.000000  \n75%     16391.500000    564.000000  9.940500e+03   17945.500000    1736.500000  \nmax    885333.000000  78831.000000  2.464364e+06  769743.000000  200201.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2000D</th>\n      <th>2000R</th>\n      <th>2000O</th>\n      <th>2004D</th>\n      <th>2004R</th>\n      <th>2004O</th>\n      <th>2008D</th>\n      <th>2008R</th>\n      <th>2008O</th>\n      <th>2012D</th>\n      <th>2012R</th>\n      <th>2012O</th>\n      <th>2016D</th>\n      <th>2016R</th>\n      <th>2016O</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.699424e+04</td>\n      <td>16533.856000</td>\n      <td>1352.073391</td>\n      <td>1.956915e+04</td>\n      <td>2.028555e+04</td>\n      <td>508.671652</td>\n      <td>2.298134e+04</td>\n      <td>19539.632696</td>\n      <td>610.991304</td>\n      <td>2.171365e+04</td>\n      <td>19761.090783</td>\n      <td>886.516522</td>\n      <td>2.175607e+04</td>\n      <td>20524.178783</td>\n      <td>2543.772522</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.942532e+04</td>\n      <td>39923.542134</td>\n      <td>4232.141433</td>\n      <td>6.769202e+04</td>\n      <td>4.869764e+04</td>\n      <td>1976.171276</td>\n      <td>7.944593e+04</td>\n      <td>45955.629730</td>\n      <td>1913.652362</td>\n      <td>7.628626e+04</td>\n      <td>45649.528293</td>\n      <td>3056.034805</td>\n      <td>8.298175e+04</td>\n      <td>44262.493478</td>\n      <td>7726.198627</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.400000e+01</td>\n      <td>106.000000</td>\n      <td>3.000000</td>\n      <td>1.200000e+01</td>\n      <td>6.500000e+01</td>\n      <td>0.000000</td>\n      <td>8.000000e+00</td>\n      <td>67.000000</td>\n      <td>0.000000</td>\n      <td>5.000000e+00</td>\n      <td>54.000000</td>\n      <td>1.000000</td>\n      <td>4.000000e+00</td>\n      <td>58.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.751500e+03</td>\n      <td>2689.000000</td>\n      <td>109.000000</td>\n      <td>1.882500e+03</td>\n      <td>3.124500e+03</td>\n      <td>43.000000</td>\n      <td>1.930500e+03</td>\n      <td>2956.000000</td>\n      <td>78.500000</td>\n      <td>1.662500e+03</td>\n      <td>3021.500000</td>\n      <td>84.000000</td>\n      <td>1.240000e+03</td>\n      <td>3346.000000</td>\n      <td>195.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.830000e+03</td>\n      <td>5363.000000</td>\n      <td>278.000000</td>\n      <td>4.177000e+03</td>\n      <td>6.522000e+03</td>\n      <td>98.000000</td>\n      <td>4.493000e+03</td>\n      <td>6297.000000</td>\n      <td>182.000000</td>\n      <td>4.014000e+03</td>\n      <td>6398.000000</td>\n      <td>195.000000</td>\n      <td>3.199000e+03</td>\n      <td>7194.000000</td>\n      <td>529.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.580500e+03</td>\n      <td>13166.000000</td>\n      <td>886.500000</td>\n      <td>1.078350e+04</td>\n      <td>1.646800e+04</td>\n      <td>302.000000</td>\n      <td>1.262450e+04</td>\n      <td>16042.000000</td>\n      <td>453.500000</td>\n      <td>1.147700e+04</td>\n      <td>16391.500000</td>\n      <td>564.000000</td>\n      <td>9.940500e+03</td>\n      <td>17945.500000</td>\n      <td>1736.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.710505e+06</td>\n      <td>871930.000000</td>\n      <td>112719.000000</td>\n      <td>1.907736e+06</td>\n      <td>1.076225e+06</td>\n      <td>39515.000000</td>\n      <td>2.295853e+06</td>\n      <td>956425.000000</td>\n      <td>65970.000000</td>\n      <td>2.216903e+06</td>\n      <td>885333.000000</td>\n      <td>78831.000000</td>\n      <td>2.464364e+06</td>\n      <td>769743.000000</td>\n      <td>200201.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "0-LVluzeSp4P"
   },
   "source": [
    "data = data.to_numpy(dtype=np.int64)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YMNKgPOuSp5D"
   },
   "source": [
    "def plotCounty(state,county,d,r,o,predicted=None):\n",
    "    years = range(2000,2020,4)\n",
    "    plt.figure()\n",
    "    plt.plot(years,d,'b',label='Democrat')\n",
    "    plt.plot(years,r,'r',label='Republican')\n",
    "    plt.plot(years,o,'y',label='Other')\n",
    "    plt.plot(years,d+r+o,'k',label='Total')\n",
    "    if predicted is not None:\n",
    "        new_years = range(2008,2024,4)\n",
    "        plt.plot(new_years,predicted[0]*20000,'c',label='Democrat Model')\n",
    "        plt.plot(new_years,predicted[1]*20000,'m',label='Republican Model')\n",
    "        plt.plot(new_years,predicted[2]*250,'g',label='Other Model')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Votes')\n",
    "    plt.title(county+', '+state)\n",
    "    plt.xticks(years)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "DJh6SpbjSp5s"
   },
   "source": [
    "def calcState(state):\n",
    "    state_df = df[df['state']==state]\n",
    "    state_df = state_df.drop(columns=['state','county'])\n",
    "    state_votes = state_df.values.tolist()\n",
    "    state_votes = np.array(state_votes)\n",
    "    state_votes = np.sum(state_votes,axis=0,dtype=np.int64)\n",
    "    d = []\n",
    "    r = []\n",
    "    o = []\n",
    "    for ind, val in enumerate(state_votes):\n",
    "        party = ind % 3\n",
    "        if party == 0:\n",
    "            d.append(val)\n",
    "        elif party == 1:\n",
    "            r.append(val)\n",
    "        else:\n",
    "            o.append(val)\n",
    "    d = np.array(d)\n",
    "    r = np.array(r)\n",
    "    o = np.array(o)\n",
    "    return d,r,o"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Ir1pXANGSp6F"
   },
   "source": [
    "def plotState(state,d,r,o):\n",
    "    years = range(2000,2020,4)\n",
    "    plt.figure()\n",
    "    plt.plot(years,d,'b',label='Democrat')\n",
    "    plt.plot(years,r,'r',label='Republican')\n",
    "    plt.plot(years,o,'y',label='Other')\n",
    "    plt.plot(years,d+r+o,'k',label='Total')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Votes')\n",
    "    plt.title(state)\n",
    "    plt.xticks(years)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "BhlfhjBISp6o"
   },
   "source": [
    "def convertbyParty(point):\n",
    "    d = point[:,::3]/20000\n",
    "    r = point[:,1::3]/20000\n",
    "    o = point[:,2::3]/250\n",
    "    return d,r,o"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sKpS8inlSp7A"
   },
   "source": [
    "def getDataset(data,batch_size,split=True):\n",
    "    data = np.expand_dims(data,axis=-1)\n",
    "    np.random.shuffle(data)\n",
    "    num = data.shape[0]\n",
    "    train_data = data[:int(num*0.6)]\n",
    "    val_data = data[int(num*0.6):int(num*0.8)]\n",
    "    test_data = data[int(num*0.8):]\n",
    "    def createDS(point,label=True):\n",
    "        d,r,o=convertbyParty(point)\n",
    "        new_data = np.vstack((d,r,o))\n",
    "        ds = tf.data.Dataset.from_tensor_slices(new_data)\n",
    "        if label:\n",
    "            ds = ds.map(lambda p: (p[:-1],p[1:]))\n",
    "        else:\n",
    "            ds = ds.map(lambda p: p[:-1])\n",
    "        return ds.batch(batch_size).prefetch(1)\n",
    "    if split:\n",
    "        return createDS(train_data),createDS(val_data),createDS(test_data)\n",
    "    else:\n",
    "        return createDS(data,False)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "FuRS8y-8Sp7O",
    "outputId": "06c0bf7e-09ba-4bbf-fe63-c8bffe863076",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "train_ds, val_ds, test_ds = getDataset(data,8)\n",
    "train_ds\n"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: ((None, 4, 1), (None, 4, 1)), types: (tf.float64, tf.float64)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bHcc7PIxSp7h"
   },
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(8,2,activation='relu',input_shape=(4,1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4,activation='relu'),\n",
    "    tf.keras.layers.Reshape((4,1)),\n",
    "    tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "    tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "    tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "])\n",
    "for i in [2,4,8,16,32]:\n",
    "    model.add(tf.keras.layers.Dense(i,'relu'))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bKa-U7wESp7w"
   },
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv1D(4,2,input_shape=(4,1),activation='relu'),\n",
    "#     tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(16,return_sequences=True),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(4),\n",
    "#     tf.keras.layers.Reshape((4,1))\n",
    "# ])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Sm_qpTzDSp7-",
    "outputId": "2395e3bf-8adc-4027-a3ec-a449504c2a92",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    }
   },
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=10**(-4.5))\n",
    "model.compile(loss=tf.keras.losses.Huber(),optimizer=optimizer,metrics=['mae','mse'])\n",
    "model.summary()"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 3, 8)              24        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 100       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 1)              0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 4, 8)              320       \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 4, 8)              544       \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 4, 8)              544       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4, 2)              18        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4, 4)              12        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4, 8)              40        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4, 16)             144       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4, 32)             544       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4, 1)              33        \n",
      "=================================================================\n",
      "Total params: 2,323\n",
      "Trainable params: 2,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SR-cfHLeSp8N"
   },
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"checkpoint4.h5\", save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=125)\n"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lmf1QmWbSp8c",
    "outputId": "78e6820d-a73b-40ac-edc0-f1eb73376a7c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# history = model.fit(train_ds,epochs=80,validation_data=val_ds,callbacks=[lr_schedule])\n",
    "# plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "# plt.axis([1e-7, .01, 0, 300])\n",
    "def getlr(epoch):\n",
    "  return 10**(-epoch//150-4)\n",
    "new_lr = tf.keras.callbacks.LearningRateScheduler(getlr)\n",
    "model.fit(train_ds,epochs=10000,validation_data=val_ds,callbacks=[model_checkpoint,early_stopping,new_lr])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3057 - mae: 0.4299 - mse: 18.9972 - val_loss: 0.3185 - val_mae: 0.4824 - val_mse: 16.4637\n",
      "Epoch 2/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3100 - mae: 0.4522 - mse: 18.5880 - val_loss: 0.3045 - val_mae: 0.4629 - val_mse: 16.8060\n",
      "Epoch 3/10000\n",
      "647/647 [==============================] - 10s 16ms/step - loss: 0.3053 - mae: 0.4348 - mse: 18.5657 - val_loss: 0.3034 - val_mae: 0.4614 - val_mse: 16.8025\n",
      "Epoch 4/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3047 - mae: 0.4330 - mse: 18.5536 - val_loss: 0.3029 - val_mae: 0.4603 - val_mse: 16.7956\n",
      "Epoch 5/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3044 - mae: 0.4324 - mse: 18.5464 - val_loss: 0.3026 - val_mae: 0.4598 - val_mse: 16.8011\n",
      "Epoch 6/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3042 - mae: 0.4320 - mse: 18.5388 - val_loss: 0.3024 - val_mae: 0.4593 - val_mse: 16.8018\n",
      "Epoch 7/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3041 - mae: 0.4317 - mse: 18.5298 - val_loss: 0.3022 - val_mae: 0.4591 - val_mse: 16.8021\n",
      "Epoch 8/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3039 - mae: 0.4315 - mse: 18.5212 - val_loss: 0.3020 - val_mae: 0.4589 - val_mse: 16.8041\n",
      "Epoch 9/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3038 - mae: 0.4312 - mse: 18.5122 - val_loss: 0.3018 - val_mae: 0.4586 - val_mse: 16.7987\n",
      "Epoch 10/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3037 - mae: 0.4310 - mse: 18.5019 - val_loss: 0.3016 - val_mae: 0.4584 - val_mse: 16.7970\n",
      "Epoch 11/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3036 - mae: 0.4309 - mse: 18.4916 - val_loss: 0.3014 - val_mae: 0.4582 - val_mse: 16.7966\n",
      "Epoch 12/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3035 - mae: 0.4307 - mse: 18.4809 - val_loss: 0.3012 - val_mae: 0.4578 - val_mse: 16.7887\n",
      "Epoch 13/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3034 - mae: 0.4305 - mse: 18.4695 - val_loss: 0.3010 - val_mae: 0.4574 - val_mse: 16.7852\n",
      "Epoch 14/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3033 - mae: 0.4304 - mse: 18.4585 - val_loss: 0.3008 - val_mae: 0.4572 - val_mse: 16.7844\n",
      "Epoch 15/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3032 - mae: 0.4302 - mse: 18.4477 - val_loss: 0.3006 - val_mae: 0.4568 - val_mse: 16.7763\n",
      "Epoch 16/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3031 - mae: 0.4300 - mse: 18.4358 - val_loss: 0.3003 - val_mae: 0.4565 - val_mse: 16.7713\n",
      "Epoch 17/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3030 - mae: 0.4299 - mse: 18.4246 - val_loss: 0.3002 - val_mae: 0.4563 - val_mse: 16.7706\n",
      "Epoch 18/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3029 - mae: 0.4297 - mse: 18.4132 - val_loss: 0.2999 - val_mae: 0.4557 - val_mse: 16.7632\n",
      "Epoch 19/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3028 - mae: 0.4296 - mse: 18.4007 - val_loss: 0.2997 - val_mae: 0.4555 - val_mse: 16.7569\n",
      "Epoch 20/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3027 - mae: 0.4295 - mse: 18.3889 - val_loss: 0.2996 - val_mae: 0.4553 - val_mse: 16.7544\n",
      "Epoch 21/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3026 - mae: 0.4293 - mse: 18.3775 - val_loss: 0.2994 - val_mae: 0.4548 - val_mse: 16.7451\n",
      "Epoch 22/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3026 - mae: 0.4292 - mse: 18.3650 - val_loss: 0.2992 - val_mae: 0.4545 - val_mse: 16.7381\n",
      "Epoch 23/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3025 - mae: 0.4290 - mse: 18.3539 - val_loss: 0.2990 - val_mae: 0.4543 - val_mse: 16.7371\n",
      "Epoch 24/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3024 - mae: 0.4289 - mse: 18.3425 - val_loss: 0.2989 - val_mae: 0.4539 - val_mse: 16.7286\n",
      "Epoch 25/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3023 - mae: 0.4288 - mse: 18.3309 - val_loss: 0.2987 - val_mae: 0.4536 - val_mse: 16.7247\n",
      "Epoch 26/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3022 - mae: 0.4286 - mse: 18.3198 - val_loss: 0.2985 - val_mae: 0.4534 - val_mse: 16.7235\n",
      "Epoch 27/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3021 - mae: 0.4285 - mse: 18.3090 - val_loss: 0.2984 - val_mae: 0.4530 - val_mse: 16.7151\n",
      "Epoch 28/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3021 - mae: 0.4283 - mse: 18.2974 - val_loss: 0.2982 - val_mae: 0.4528 - val_mse: 16.7108\n",
      "Epoch 29/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3020 - mae: 0.4282 - mse: 18.2868 - val_loss: 0.2981 - val_mae: 0.4526 - val_mse: 16.7111\n",
      "Epoch 30/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3019 - mae: 0.4281 - mse: 18.2757 - val_loss: 0.2979 - val_mae: 0.4522 - val_mse: 16.7034\n",
      "Epoch 31/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3018 - mae: 0.4280 - mse: 18.2636 - val_loss: 0.2978 - val_mae: 0.4520 - val_mse: 16.6982\n",
      "Epoch 32/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3017 - mae: 0.4278 - mse: 18.2521 - val_loss: 0.2976 - val_mae: 0.4518 - val_mse: 16.6961\n",
      "Epoch 33/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3017 - mae: 0.4277 - mse: 18.2419 - val_loss: 0.2975 - val_mae: 0.4515 - val_mse: 16.6891\n",
      "Epoch 34/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3016 - mae: 0.4275 - mse: 18.2298 - val_loss: 0.2973 - val_mae: 0.4512 - val_mse: 16.6833\n",
      "Epoch 35/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3015 - mae: 0.4274 - mse: 18.2192 - val_loss: 0.2972 - val_mae: 0.4511 - val_mse: 16.6825\n",
      "Epoch 36/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3014 - mae: 0.4273 - mse: 18.2077 - val_loss: 0.2971 - val_mae: 0.4507 - val_mse: 16.6737\n",
      "Epoch 37/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3013 - mae: 0.4272 - mse: 18.1960 - val_loss: 0.2969 - val_mae: 0.4505 - val_mse: 16.6687\n",
      "Epoch 38/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3013 - mae: 0.4270 - mse: 18.1855 - val_loss: 0.2969 - val_mae: 0.4506 - val_mse: 16.6669\n",
      "Epoch 39/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3012 - mae: 0.4269 - mse: 18.1743 - val_loss: 0.2967 - val_mae: 0.4502 - val_mse: 16.6584\n",
      "Epoch 40/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3011 - mae: 0.4268 - mse: 18.1624 - val_loss: 0.2965 - val_mae: 0.4499 - val_mse: 16.6530\n",
      "Epoch 41/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3010 - mae: 0.4266 - mse: 18.1522 - val_loss: 0.2964 - val_mae: 0.4498 - val_mse: 16.6526\n",
      "Epoch 42/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3010 - mae: 0.4265 - mse: 18.1408 - val_loss: 0.2963 - val_mae: 0.4494 - val_mse: 16.6442\n",
      "Epoch 43/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3009 - mae: 0.4264 - mse: 18.1291 - val_loss: 0.2961 - val_mae: 0.4492 - val_mse: 16.6394\n",
      "Epoch 44/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3008 - mae: 0.4263 - mse: 18.1187 - val_loss: 0.2961 - val_mae: 0.4492 - val_mse: 16.6386\n",
      "Epoch 45/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3007 - mae: 0.4262 - mse: 18.1074 - val_loss: 0.2959 - val_mae: 0.4488 - val_mse: 16.6302\n",
      "Epoch 46/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3007 - mae: 0.4260 - mse: 18.0954 - val_loss: 0.2958 - val_mae: 0.4485 - val_mse: 16.6254\n",
      "Epoch 47/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3006 - mae: 0.4259 - mse: 18.0842 - val_loss: 0.2956 - val_mae: 0.4484 - val_mse: 16.6230\n",
      "Epoch 48/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3005 - mae: 0.4257 - mse: 18.0739 - val_loss: 0.2955 - val_mae: 0.4481 - val_mse: 16.6165\n",
      "Epoch 49/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3004 - mae: 0.4256 - mse: 18.0619 - val_loss: 0.2954 - val_mae: 0.4479 - val_mse: 16.6112\n",
      "Epoch 50/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3004 - mae: 0.4255 - mse: 18.0508 - val_loss: 0.2953 - val_mae: 0.4478 - val_mse: 16.6094\n",
      "Epoch 51/10000\n",
      "647/647 [==============================] - 10s 16ms/step - loss: 0.3003 - mae: 0.4254 - mse: 18.0394 - val_loss: 0.2951 - val_mae: 0.4473 - val_mse: 16.6021\n",
      "Epoch 52/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3002 - mae: 0.4253 - mse: 18.0275 - val_loss: 0.2950 - val_mae: 0.4471 - val_mse: 16.5973\n",
      "Epoch 53/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.3001 - mae: 0.4251 - mse: 18.0164 - val_loss: 0.2949 - val_mae: 0.4471 - val_mse: 16.5952\n",
      "Epoch 54/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.3001 - mae: 0.4250 - mse: 18.0048 - val_loss: 0.2948 - val_mae: 0.4468 - val_mse: 16.5865\n",
      "Epoch 55/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.3000 - mae: 0.4249 - mse: 17.9927 - val_loss: 0.2946 - val_mae: 0.4463 - val_mse: 16.5815\n",
      "Epoch 56/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2999 - mae: 0.4247 - mse: 17.9821 - val_loss: 0.2945 - val_mae: 0.4462 - val_mse: 16.5803\n",
      "Epoch 57/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2998 - mae: 0.4246 - mse: 17.9704 - val_loss: 0.2943 - val_mae: 0.4457 - val_mse: 16.5720\n",
      "Epoch 58/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2998 - mae: 0.4245 - mse: 17.9583 - val_loss: 0.2942 - val_mae: 0.4456 - val_mse: 16.5667\n",
      "Epoch 59/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2997 - mae: 0.4244 - mse: 17.9471 - val_loss: 0.2941 - val_mae: 0.4455 - val_mse: 16.5646\n",
      "Epoch 60/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2996 - mae: 0.4243 - mse: 17.9358 - val_loss: 0.2940 - val_mae: 0.4451 - val_mse: 16.5567\n",
      "Epoch 61/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2996 - mae: 0.4242 - mse: 17.9240 - val_loss: 0.2939 - val_mae: 0.4449 - val_mse: 16.5521\n",
      "Epoch 62/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2995 - mae: 0.4240 - mse: 17.9128 - val_loss: 0.2938 - val_mae: 0.4449 - val_mse: 16.5501\n",
      "Epoch 63/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2994 - mae: 0.4239 - mse: 17.9017 - val_loss: 0.2937 - val_mae: 0.4445 - val_mse: 16.5425\n",
      "Epoch 64/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2993 - mae: 0.4238 - mse: 17.8898 - val_loss: 0.2935 - val_mae: 0.4443 - val_mse: 16.5383\n",
      "Epoch 65/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2993 - mae: 0.4237 - mse: 17.8788 - val_loss: 0.2934 - val_mae: 0.4442 - val_mse: 16.5364\n",
      "Epoch 66/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2992 - mae: 0.4236 - mse: 17.8676 - val_loss: 0.2933 - val_mae: 0.4439 - val_mse: 16.5290\n",
      "Epoch 67/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2991 - mae: 0.4235 - mse: 17.8558 - val_loss: 0.2932 - val_mae: 0.4438 - val_mse: 16.5245\n",
      "Epoch 68/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2991 - mae: 0.4233 - mse: 17.8450 - val_loss: 0.2931 - val_mae: 0.4436 - val_mse: 16.5225\n",
      "Epoch 69/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2990 - mae: 0.4232 - mse: 17.8336 - val_loss: 0.2930 - val_mae: 0.4433 - val_mse: 16.5148\n",
      "Epoch 70/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2989 - mae: 0.4231 - mse: 17.8218 - val_loss: 0.2929 - val_mae: 0.4431 - val_mse: 16.5104\n",
      "Epoch 71/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2989 - mae: 0.4230 - mse: 17.8109 - val_loss: 0.2928 - val_mae: 0.4430 - val_mse: 16.5086\n",
      "Epoch 72/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2988 - mae: 0.4229 - mse: 17.7996 - val_loss: 0.2926 - val_mae: 0.4427 - val_mse: 16.5011\n",
      "Epoch 73/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2987 - mae: 0.4228 - mse: 17.7879 - val_loss: 0.2926 - val_mae: 0.4426 - val_mse: 16.4996\n",
      "Epoch 74/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2986 - mae: 0.4227 - mse: 17.7771 - val_loss: 0.2924 - val_mae: 0.4423 - val_mse: 16.4921\n",
      "Epoch 75/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2986 - mae: 0.4225 - mse: 17.7653 - val_loss: 0.2923 - val_mae: 0.4421 - val_mse: 16.4879\n",
      "Epoch 76/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2985 - mae: 0.4224 - mse: 17.7540 - val_loss: 0.2922 - val_mae: 0.4420 - val_mse: 16.4861\n",
      "Epoch 77/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2984 - mae: 0.4223 - mse: 17.7432 - val_loss: 0.2921 - val_mae: 0.4417 - val_mse: 16.4785\n",
      "Epoch 78/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2984 - mae: 0.4222 - mse: 17.7310 - val_loss: 0.2920 - val_mae: 0.4415 - val_mse: 16.4738\n",
      "Epoch 79/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2983 - mae: 0.4221 - mse: 17.7197 - val_loss: 0.2919 - val_mae: 0.4414 - val_mse: 16.4716\n",
      "Epoch 80/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2982 - mae: 0.4220 - mse: 17.7087 - val_loss: 0.2918 - val_mae: 0.4411 - val_mse: 16.4635\n",
      "Epoch 81/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2982 - mae: 0.4219 - mse: 17.6966 - val_loss: 0.2917 - val_mae: 0.4410 - val_mse: 16.4595\n",
      "Epoch 82/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2981 - mae: 0.4218 - mse: 17.6854 - val_loss: 0.2916 - val_mae: 0.4409 - val_mse: 16.4573\n",
      "Epoch 83/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2980 - mae: 0.4217 - mse: 17.6743 - val_loss: 0.2915 - val_mae: 0.4406 - val_mse: 16.4494\n",
      "Epoch 84/10000\n",
      "647/647 [==============================] - 10s 16ms/step - loss: 0.2980 - mae: 0.4216 - mse: 17.6628 - val_loss: 0.2915 - val_mae: 0.4406 - val_mse: 16.4453\n",
      "Epoch 85/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2979 - mae: 0.4215 - mse: 17.6520 - val_loss: 0.2914 - val_mae: 0.4405 - val_mse: 16.4437\n",
      "Epoch 86/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2978 - mae: 0.4214 - mse: 17.6406 - val_loss: 0.2913 - val_mae: 0.4402 - val_mse: 16.4358\n",
      "Epoch 87/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2978 - mae: 0.4213 - mse: 17.6292 - val_loss: 0.2912 - val_mae: 0.4402 - val_mse: 16.4347\n",
      "Epoch 88/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2977 - mae: 0.4212 - mse: 17.6185 - val_loss: 0.2911 - val_mae: 0.4399 - val_mse: 16.4274\n",
      "Epoch 89/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2976 - mae: 0.4210 - mse: 17.6069 - val_loss: 0.2910 - val_mae: 0.4397 - val_mse: 16.4234\n",
      "Epoch 90/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2976 - mae: 0.4209 - mse: 17.5957 - val_loss: 0.2909 - val_mae: 0.4396 - val_mse: 16.4219\n",
      "Epoch 91/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2975 - mae: 0.4208 - mse: 17.5847 - val_loss: 0.2907 - val_mae: 0.4393 - val_mse: 16.4144\n",
      "Epoch 92/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2974 - mae: 0.4207 - mse: 17.5730 - val_loss: 0.2906 - val_mae: 0.4392 - val_mse: 16.4105\n",
      "Epoch 93/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2974 - mae: 0.4206 - mse: 17.5619 - val_loss: 0.2906 - val_mae: 0.4391 - val_mse: 16.4089\n",
      "Epoch 94/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2973 - mae: 0.4205 - mse: 17.5508 - val_loss: 0.2904 - val_mae: 0.4388 - val_mse: 16.4016\n",
      "Epoch 95/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2972 - mae: 0.4204 - mse: 17.5390 - val_loss: 0.2903 - val_mae: 0.4386 - val_mse: 16.3976\n",
      "Epoch 96/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2972 - mae: 0.4203 - mse: 17.5281 - val_loss: 0.2902 - val_mae: 0.4386 - val_mse: 16.3961\n",
      "Epoch 97/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2971 - mae: 0.4202 - mse: 17.5166 - val_loss: 0.2901 - val_mae: 0.4382 - val_mse: 16.3886\n",
      "Epoch 98/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2970 - mae: 0.4201 - mse: 17.5049 - val_loss: 0.2900 - val_mae: 0.4381 - val_mse: 16.3847\n",
      "Epoch 99/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2970 - mae: 0.4200 - mse: 17.4936 - val_loss: 0.2899 - val_mae: 0.4380 - val_mse: 16.3832\n",
      "Epoch 100/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2969 - mae: 0.4199 - mse: 17.4822 - val_loss: 0.2898 - val_mae: 0.4377 - val_mse: 16.3759\n",
      "Epoch 101/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2968 - mae: 0.4198 - mse: 17.4703 - val_loss: 0.2897 - val_mae: 0.4375 - val_mse: 16.3722\n",
      "Epoch 102/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2968 - mae: 0.4197 - mse: 17.4593 - val_loss: 0.2896 - val_mae: 0.4374 - val_mse: 16.3711\n",
      "Epoch 103/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2967 - mae: 0.4196 - mse: 17.4478 - val_loss: 0.2895 - val_mae: 0.4371 - val_mse: 16.3641\n",
      "Epoch 104/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2966 - mae: 0.4195 - mse: 17.4358 - val_loss: 0.2894 - val_mae: 0.4369 - val_mse: 16.3627\n",
      "Epoch 105/10000\n",
      "647/647 [==============================] - 9s 14ms/step - loss: 0.2966 - mae: 0.4194 - mse: 17.4246 - val_loss: 0.2893 - val_mae: 0.4366 - val_mse: 16.3551\n",
      "Epoch 106/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2965 - mae: 0.4193 - mse: 17.4124 - val_loss: 0.2891 - val_mae: 0.4364 - val_mse: 16.3510\n",
      "Epoch 107/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2964 - mae: 0.4192 - mse: 17.4009 - val_loss: 0.2890 - val_mae: 0.4363 - val_mse: 16.3495\n",
      "Epoch 108/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2964 - mae: 0.4190 - mse: 17.3897 - val_loss: 0.2889 - val_mae: 0.4360 - val_mse: 16.3422\n",
      "Epoch 109/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2963 - mae: 0.4189 - mse: 17.3777 - val_loss: 0.2888 - val_mae: 0.4358 - val_mse: 16.3383\n",
      "Epoch 110/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2962 - mae: 0.4188 - mse: 17.3661 - val_loss: 0.2887 - val_mae: 0.4356 - val_mse: 16.3367\n",
      "Epoch 111/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2962 - mae: 0.4187 - mse: 17.3549 - val_loss: 0.2886 - val_mae: 0.4353 - val_mse: 16.3295\n",
      "Epoch 112/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2961 - mae: 0.4186 - mse: 17.3428 - val_loss: 0.2885 - val_mae: 0.4352 - val_mse: 16.3257\n",
      "Epoch 113/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2960 - mae: 0.4185 - mse: 17.3311 - val_loss: 0.2884 - val_mae: 0.4350 - val_mse: 16.3235\n",
      "Epoch 114/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2960 - mae: 0.4184 - mse: 17.3195 - val_loss: 0.2883 - val_mae: 0.4348 - val_mse: 16.3152\n",
      "Epoch 115/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2959 - mae: 0.4183 - mse: 17.3071 - val_loss: 0.2882 - val_mae: 0.4347 - val_mse: 16.3106\n",
      "Epoch 116/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2959 - mae: 0.4182 - mse: 17.2955 - val_loss: 0.2881 - val_mae: 0.4346 - val_mse: 16.3083\n",
      "Epoch 117/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2958 - mae: 0.4181 - mse: 17.2839 - val_loss: 0.2880 - val_mae: 0.4343 - val_mse: 16.2998\n",
      "Epoch 118/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2957 - mae: 0.4180 - mse: 17.2714 - val_loss: 0.2879 - val_mae: 0.4341 - val_mse: 16.2958\n",
      "Epoch 119/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2957 - mae: 0.4179 - mse: 17.2598 - val_loss: 0.2878 - val_mae: 0.4340 - val_mse: 16.2935\n",
      "Epoch 120/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2956 - mae: 0.4178 - mse: 17.2480 - val_loss: 0.2877 - val_mae: 0.4336 - val_mse: 16.2847\n",
      "Epoch 121/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2955 - mae: 0.4177 - mse: 17.2355 - val_loss: 0.2876 - val_mae: 0.4335 - val_mse: 16.2801\n",
      "Epoch 122/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2955 - mae: 0.4176 - mse: 17.2240 - val_loss: 0.2875 - val_mae: 0.4333 - val_mse: 16.2782\n",
      "Epoch 123/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2954 - mae: 0.4175 - mse: 17.2123 - val_loss: 0.2874 - val_mae: 0.4330 - val_mse: 16.2697\n",
      "Epoch 124/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2953 - mae: 0.4174 - mse: 17.1996 - val_loss: 0.2873 - val_mae: 0.4329 - val_mse: 16.2654\n",
      "Epoch 125/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2953 - mae: 0.4173 - mse: 17.1881 - val_loss: 0.2872 - val_mae: 0.4328 - val_mse: 16.2636\n",
      "Epoch 126/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2952 - mae: 0.4172 - mse: 17.1763 - val_loss: 0.2871 - val_mae: 0.4325 - val_mse: 16.2556\n",
      "Epoch 127/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2951 - mae: 0.4171 - mse: 17.1640 - val_loss: 0.2870 - val_mae: 0.4325 - val_mse: 16.2544\n",
      "Epoch 128/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2951 - mae: 0.4170 - mse: 17.1528 - val_loss: 0.2869 - val_mae: 0.4322 - val_mse: 16.2464\n",
      "Epoch 129/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2950 - mae: 0.4169 - mse: 17.1401 - val_loss: 0.2868 - val_mae: 0.4319 - val_mse: 16.2416\n",
      "Epoch 130/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2949 - mae: 0.4168 - mse: 17.1286 - val_loss: 0.2867 - val_mae: 0.4319 - val_mse: 16.2407\n",
      "Epoch 131/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2949 - mae: 0.4166 - mse: 17.1169 - val_loss: 0.2866 - val_mae: 0.4316 - val_mse: 16.2327\n",
      "Epoch 132/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2948 - mae: 0.4165 - mse: 17.1045 - val_loss: 0.2865 - val_mae: 0.4314 - val_mse: 16.2287\n",
      "Epoch 133/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2947 - mae: 0.4164 - mse: 17.0931 - val_loss: 0.2864 - val_mae: 0.4312 - val_mse: 16.2272\n",
      "Epoch 134/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2947 - mae: 0.4163 - mse: 17.0813 - val_loss: 0.2863 - val_mae: 0.4309 - val_mse: 16.2192\n",
      "Epoch 135/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2946 - mae: 0.4162 - mse: 17.0687 - val_loss: 0.2862 - val_mae: 0.4308 - val_mse: 16.2148\n",
      "Epoch 136/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2945 - mae: 0.4161 - mse: 17.0573 - val_loss: 0.2861 - val_mae: 0.4307 - val_mse: 16.2129\n",
      "Epoch 137/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2945 - mae: 0.4160 - mse: 17.0454 - val_loss: 0.2860 - val_mae: 0.4304 - val_mse: 16.2048\n",
      "Epoch 138/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2944 - mae: 0.4159 - mse: 17.0328 - val_loss: 0.2859 - val_mae: 0.4303 - val_mse: 16.2002\n",
      "Epoch 139/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2943 - mae: 0.4158 - mse: 17.0211 - val_loss: 0.2858 - val_mae: 0.4303 - val_mse: 16.1985\n",
      "Epoch 140/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2943 - mae: 0.4157 - mse: 17.0090 - val_loss: 0.2857 - val_mae: 0.4300 - val_mse: 16.1900\n",
      "Epoch 141/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2942 - mae: 0.4156 - mse: 16.9960 - val_loss: 0.2856 - val_mae: 0.4298 - val_mse: 16.1853\n",
      "Epoch 142/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2941 - mae: 0.4155 - mse: 16.9842 - val_loss: 0.2855 - val_mae: 0.4297 - val_mse: 16.1833\n",
      "Epoch 143/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2941 - mae: 0.4154 - mse: 16.9722 - val_loss: 0.2854 - val_mae: 0.4294 - val_mse: 16.1753\n",
      "Epoch 144/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2940 - mae: 0.4152 - mse: 16.9593 - val_loss: 0.2853 - val_mae: 0.4292 - val_mse: 16.1706\n",
      "Epoch 145/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4151 - mse: 16.9473 - val_loss: 0.2853 - val_mae: 0.4291 - val_mse: 16.1685\n",
      "Epoch 146/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4150 - mse: 16.9353 - val_loss: 0.2852 - val_mae: 0.4288 - val_mse: 16.1602\n",
      "Epoch 147/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2938 - mae: 0.4149 - mse: 16.9224 - val_loss: 0.2851 - val_mae: 0.4287 - val_mse: 16.1560\n",
      "Epoch 148/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4148 - mse: 16.9103 - val_loss: 0.2850 - val_mae: 0.4286 - val_mse: 16.1533\n",
      "Epoch 149/10000\n",
      "647/647 [==============================] - 10s 16ms/step - loss: 0.2937 - mae: 0.4147 - mse: 16.8982 - val_loss: 0.2849 - val_mae: 0.4283 - val_mse: 16.1450\n",
      "Epoch 150/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2936 - mae: 0.4146 - mse: 16.8851 - val_loss: 0.2848 - val_mae: 0.4281 - val_mse: 16.1402\n",
      "Epoch 151/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2935 - mae: 0.4145 - mse: 16.8729 - val_loss: 0.2847 - val_mae: 0.4280 - val_mse: 16.1378\n",
      "Epoch 152/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2969 - mae: 0.4216 - mse: 16.8172 - val_loss: 0.2786 - val_mae: 0.4066 - val_mse: 16.2780\n",
      "Epoch 153/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2951 - mae: 0.4168 - mse: 16.8338 - val_loss: 0.2784 - val_mae: 0.4064 - val_mse: 16.3331\n",
      "Epoch 154/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2947 - mae: 0.4157 - mse: 16.8445 - val_loss: 0.2783 - val_mae: 0.4064 - val_mse: 16.3631\n",
      "Epoch 155/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2946 - mae: 0.4152 - mse: 16.8506 - val_loss: 0.2782 - val_mae: 0.4063 - val_mse: 16.3795\n",
      "Epoch 156/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2944 - mae: 0.4148 - mse: 16.8537 - val_loss: 0.2781 - val_mae: 0.4061 - val_mse: 16.3896\n",
      "Epoch 157/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2943 - mae: 0.4145 - mse: 16.8553 - val_loss: 0.2780 - val_mae: 0.4060 - val_mse: 16.3958\n",
      "Epoch 158/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2943 - mae: 0.4143 - mse: 16.8560 - val_loss: 0.2780 - val_mae: 0.4059 - val_mse: 16.4002\n",
      "Epoch 159/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2942 - mae: 0.4141 - mse: 16.8562 - val_loss: 0.2779 - val_mae: 0.4057 - val_mse: 16.4034\n",
      "Epoch 160/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2942 - mae: 0.4140 - mse: 16.8561 - val_loss: 0.2779 - val_mae: 0.4056 - val_mse: 16.4058\n",
      "Epoch 161/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2942 - mae: 0.4139 - mse: 16.8558 - val_loss: 0.2778 - val_mae: 0.4054 - val_mse: 16.4079\n",
      "Epoch 162/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2941 - mae: 0.4138 - mse: 16.8554 - val_loss: 0.2778 - val_mae: 0.4053 - val_mse: 16.4095\n",
      "Epoch 163/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2941 - mae: 0.4137 - mse: 16.8548 - val_loss: 0.2778 - val_mae: 0.4052 - val_mse: 16.4110\n",
      "Epoch 164/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2941 - mae: 0.4136 - mse: 16.8542 - val_loss: 0.2777 - val_mae: 0.4051 - val_mse: 16.4124\n",
      "Epoch 165/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2941 - mae: 0.4135 - mse: 16.8536 - val_loss: 0.2777 - val_mae: 0.4050 - val_mse: 16.4135\n",
      "Epoch 166/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2940 - mae: 0.4135 - mse: 16.8529 - val_loss: 0.2777 - val_mae: 0.4049 - val_mse: 16.4147\n",
      "Epoch 167/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2940 - mae: 0.4134 - mse: 16.8523 - val_loss: 0.2777 - val_mae: 0.4048 - val_mse: 16.4158\n",
      "Epoch 168/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2940 - mae: 0.4133 - mse: 16.8516 - val_loss: 0.2776 - val_mae: 0.4047 - val_mse: 16.4166\n",
      "Epoch 169/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2940 - mae: 0.4133 - mse: 16.8508 - val_loss: 0.2776 - val_mae: 0.4046 - val_mse: 16.4176\n",
      "Epoch 170/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2940 - mae: 0.4132 - mse: 16.8501 - val_loss: 0.2776 - val_mae: 0.4045 - val_mse: 16.4184\n",
      "Epoch 171/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4132 - mse: 16.8493 - val_loss: 0.2776 - val_mae: 0.4044 - val_mse: 16.4189\n",
      "Epoch 172/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4131 - mse: 16.8485 - val_loss: 0.2775 - val_mae: 0.4044 - val_mse: 16.4195\n",
      "Epoch 173/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4131 - mse: 16.8477 - val_loss: 0.2775 - val_mae: 0.4043 - val_mse: 16.4201\n",
      "Epoch 174/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4131 - mse: 16.8469 - val_loss: 0.2775 - val_mae: 0.4042 - val_mse: 16.4205\n",
      "Epoch 175/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4130 - mse: 16.8461 - val_loss: 0.2775 - val_mae: 0.4041 - val_mse: 16.4210\n",
      "Epoch 176/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2939 - mae: 0.4130 - mse: 16.8453 - val_loss: 0.2774 - val_mae: 0.4041 - val_mse: 16.4213\n",
      "Epoch 177/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2939 - mae: 0.4129 - mse: 16.8444 - val_loss: 0.2774 - val_mae: 0.4040 - val_mse: 16.4216\n",
      "Epoch 178/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2938 - mae: 0.4129 - mse: 16.8437 - val_loss: 0.2774 - val_mae: 0.4039 - val_mse: 16.4226\n",
      "Epoch 179/10000\n",
      "647/647 [==============================] - 9s 15ms/step - loss: 0.2938 - mae: 0.4129 - mse: 16.8430 - val_loss: 0.2774 - val_mae: 0.4039 - val_mse: 16.4225\n",
      "Epoch 180/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2938 - mae: 0.4128 - mse: 16.8421 - val_loss: 0.2774 - val_mae: 0.4038 - val_mse: 16.4226\n",
      "Epoch 181/10000\n",
      "647/647 [==============================] - 10s 16ms/step - loss: 0.2938 - mae: 0.4128 - mse: 16.8412 - val_loss: 0.2773 - val_mae: 0.4038 - val_mse: 16.4230\n",
      "Epoch 182/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2938 - mae: 0.4128 - mse: 16.8404 - val_loss: 0.2773 - val_mae: 0.4037 - val_mse: 16.4232\n",
      "Epoch 183/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2938 - mae: 0.4127 - mse: 16.8396 - val_loss: 0.2773 - val_mae: 0.4036 - val_mse: 16.4242\n",
      "Epoch 184/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2938 - mae: 0.4127 - mse: 16.8390 - val_loss: 0.2773 - val_mae: 0.4036 - val_mse: 16.4241\n",
      "Epoch 185/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4127 - mse: 16.8381 - val_loss: 0.2773 - val_mae: 0.4035 - val_mse: 16.4242\n",
      "Epoch 186/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4127 - mse: 16.8373 - val_loss: 0.2772 - val_mae: 0.4035 - val_mse: 16.4245\n",
      "Epoch 187/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4126 - mse: 16.8364 - val_loss: 0.2772 - val_mae: 0.4034 - val_mse: 16.4247\n",
      "Epoch 188/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4126 - mse: 16.8357 - val_loss: 0.2772 - val_mae: 0.4034 - val_mse: 16.4257\n",
      "Epoch 189/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4126 - mse: 16.8351 - val_loss: 0.2772 - val_mae: 0.4033 - val_mse: 16.4255\n",
      "Epoch 190/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4125 - mse: 16.8341 - val_loss: 0.2772 - val_mae: 0.4033 - val_mse: 16.4256\n",
      "Epoch 191/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4125 - mse: 16.8333 - val_loss: 0.2772 - val_mae: 0.4032 - val_mse: 16.4258\n",
      "Epoch 192/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2937 - mae: 0.4125 - mse: 16.8325 - val_loss: 0.2771 - val_mae: 0.4032 - val_mse: 16.4267\n",
      "Epoch 193/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2936 - mae: 0.4125 - mse: 16.8319 - val_loss: 0.2771 - val_mae: 0.4031 - val_mse: 16.4265\n",
      "Epoch 194/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2936 - mae: 0.4124 - mse: 16.8310 - val_loss: 0.2771 - val_mae: 0.4031 - val_mse: 16.4265\n",
      "Epoch 195/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2936 - mae: 0.4124 - mse: 16.8301 - val_loss: 0.2771 - val_mae: 0.4030 - val_mse: 16.4268\n",
      "Epoch 196/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2936 - mae: 0.4124 - mse: 16.8294 - val_loss: 0.2771 - val_mae: 0.4030 - val_mse: 16.4276\n",
      "Epoch 197/10000\n",
      "647/647 [==============================] - 10s 15ms/step - loss: 0.2936 - mae: 0.4124 - mse: 16.8287 - val_loss: 0.2771 - val_mae: 0.4029 - val_mse: 16.4274\n",
      "Epoch 198/10000\n",
      " 25/647 [>.............................] - ETA: 7s - loss: 0.0460 - mae: 0.1422 - mse: 0.1678"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sY9EgNpOSp8s"
   },
   "source": [
    "c = 'Autauga'\n",
    "s = 'AL'\n",
    "r = df[(df['state']==s)&(df['county']==c)]"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lCSQPQbsSp87"
   },
   "source": [
    "model4 = tf.keras.models.load_model('checkpoint4.h5')\n",
    "row = r.drop(columns=['state','county'])\n",
    "row = row.to_numpy()\n",
    "dataset = getDataset(row,2,False)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "IKZQWaW-Sp9N",
    "outputId": "a201a597-bade-49d6-fd9b-230df224ce05",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "results = model4.predict(dataset)\n",
    "print(results)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.2350704 ]\n",
      "  [0.31665772]\n",
      "  [0.29744172]\n",
      "  [0.52478254]]\n",
      "\n",
      " [[0.6701347 ]\n",
      "  [0.8887835 ]\n",
      "  [0.8544977 ]\n",
      "  [1.0203351 ]]\n",
      "\n",
      " [[0.38993528]\n",
      "  [0.7494613 ]\n",
      "  [0.752346  ]\n",
      "  [2.107971  ]]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "J-2cK6uCSp9k",
    "outputId": "73307db3-2e1e-4dd5-ff6a-62ae54c0caa9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    }
   },
   "source": [
    "dem = np.array(r.values.tolist()[0][2::3])\n",
    "gop = np.array(r.values.tolist()[0][3::3])\n",
    "other = np.array(r.values.tolist()[0][4::3])\n",
    "plotCounty(s,c,dem,gop,other,results)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotCounty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-17-65842ac2c122>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mgop\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mother\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mplotCounty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdem\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mgop\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'plotCounty' is not defined"
     ]
    }
   ]
  }
 ]
}