{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "predictCounty.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "CsluoFv7Sp2j"
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "tlcuuCFhSp3G"
   },
   "source": [
    "years = range(2000,2020,4)\n",
    "df = pd.read_csv('counties.csv')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PrR6Do9iSp3f",
    "outputId": "8ac723de-d0f5-4e58-d36c-5ebb3373e731",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    }
   },
   "source": [
    "data = df.drop(columns=['state', 'county'])\n",
    "data = data.dropna(axis=0,how='any')\n",
    "data.describe()"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "              2000D          2000R          2000O         2004D         2004R  \\\ncount  2.875000e+03    2875.000000    2875.000000  2.875000e+03  2.875000e+03   \nmean   1.699424e+04   16533.856000    1352.073391  1.956915e+04  2.028555e+04   \nstd    5.942532e+04   39923.542134    4232.141433  6.769202e+04  4.869764e+04   \nmin    1.400000e+01     106.000000       3.000000  1.200000e+01  6.500000e+01   \n25%    1.751500e+03    2689.000000     109.000000  1.882500e+03  3.124500e+03   \n50%    3.830000e+03    5363.000000     278.000000  4.177000e+03  6.522000e+03   \n75%    9.580500e+03   13166.000000     886.500000  1.078350e+04  1.646800e+04   \nmax    1.710505e+06  871930.000000  112719.000000  1.907736e+06  1.076225e+06   \n\n              2004O         2008D          2008R         2008O         2012D  \\\ncount   2875.000000  2.875000e+03    2875.000000   2875.000000  2.875000e+03   \nmean     508.671652  2.298134e+04   19539.632696    610.991304  2.171365e+04   \nstd     1976.171276  7.944593e+04   45955.629730   1913.652362  7.628626e+04   \nmin        0.000000  8.000000e+00      67.000000      0.000000  5.000000e+00   \n25%       43.000000  1.930500e+03    2956.000000     78.500000  1.662500e+03   \n50%       98.000000  4.493000e+03    6297.000000    182.000000  4.014000e+03   \n75%      302.000000  1.262450e+04   16042.000000    453.500000  1.147700e+04   \nmax    39515.000000  2.295853e+06  956425.000000  65970.000000  2.216903e+06   \n\n               2012R         2012O         2016D          2016R          2016O  \ncount    2875.000000   2875.000000  2.875000e+03    2875.000000    2875.000000  \nmean    19761.090783    886.516522  2.175607e+04   20524.178783    2543.772522  \nstd     45649.528293   3056.034805  8.298175e+04   44262.493478    7726.198627  \nmin        54.000000      1.000000  4.000000e+00      58.000000       3.000000  \n25%      3021.500000     84.000000  1.240000e+03    3346.000000     195.000000  \n50%      6398.000000    195.000000  3.199000e+03    7194.000000     529.000000  \n75%     16391.500000    564.000000  9.940500e+03   17945.500000    1736.500000  \nmax    885333.000000  78831.000000  2.464364e+06  769743.000000  200201.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2000D</th>\n      <th>2000R</th>\n      <th>2000O</th>\n      <th>2004D</th>\n      <th>2004R</th>\n      <th>2004O</th>\n      <th>2008D</th>\n      <th>2008R</th>\n      <th>2008O</th>\n      <th>2012D</th>\n      <th>2012R</th>\n      <th>2012O</th>\n      <th>2016D</th>\n      <th>2016R</th>\n      <th>2016O</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n      <td>2.875000e+03</td>\n      <td>2875.000000</td>\n      <td>2875.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.699424e+04</td>\n      <td>16533.856000</td>\n      <td>1352.073391</td>\n      <td>1.956915e+04</td>\n      <td>2.028555e+04</td>\n      <td>508.671652</td>\n      <td>2.298134e+04</td>\n      <td>19539.632696</td>\n      <td>610.991304</td>\n      <td>2.171365e+04</td>\n      <td>19761.090783</td>\n      <td>886.516522</td>\n      <td>2.175607e+04</td>\n      <td>20524.178783</td>\n      <td>2543.772522</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.942532e+04</td>\n      <td>39923.542134</td>\n      <td>4232.141433</td>\n      <td>6.769202e+04</td>\n      <td>4.869764e+04</td>\n      <td>1976.171276</td>\n      <td>7.944593e+04</td>\n      <td>45955.629730</td>\n      <td>1913.652362</td>\n      <td>7.628626e+04</td>\n      <td>45649.528293</td>\n      <td>3056.034805</td>\n      <td>8.298175e+04</td>\n      <td>44262.493478</td>\n      <td>7726.198627</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.400000e+01</td>\n      <td>106.000000</td>\n      <td>3.000000</td>\n      <td>1.200000e+01</td>\n      <td>6.500000e+01</td>\n      <td>0.000000</td>\n      <td>8.000000e+00</td>\n      <td>67.000000</td>\n      <td>0.000000</td>\n      <td>5.000000e+00</td>\n      <td>54.000000</td>\n      <td>1.000000</td>\n      <td>4.000000e+00</td>\n      <td>58.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.751500e+03</td>\n      <td>2689.000000</td>\n      <td>109.000000</td>\n      <td>1.882500e+03</td>\n      <td>3.124500e+03</td>\n      <td>43.000000</td>\n      <td>1.930500e+03</td>\n      <td>2956.000000</td>\n      <td>78.500000</td>\n      <td>1.662500e+03</td>\n      <td>3021.500000</td>\n      <td>84.000000</td>\n      <td>1.240000e+03</td>\n      <td>3346.000000</td>\n      <td>195.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.830000e+03</td>\n      <td>5363.000000</td>\n      <td>278.000000</td>\n      <td>4.177000e+03</td>\n      <td>6.522000e+03</td>\n      <td>98.000000</td>\n      <td>4.493000e+03</td>\n      <td>6297.000000</td>\n      <td>182.000000</td>\n      <td>4.014000e+03</td>\n      <td>6398.000000</td>\n      <td>195.000000</td>\n      <td>3.199000e+03</td>\n      <td>7194.000000</td>\n      <td>529.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.580500e+03</td>\n      <td>13166.000000</td>\n      <td>886.500000</td>\n      <td>1.078350e+04</td>\n      <td>1.646800e+04</td>\n      <td>302.000000</td>\n      <td>1.262450e+04</td>\n      <td>16042.000000</td>\n      <td>453.500000</td>\n      <td>1.147700e+04</td>\n      <td>16391.500000</td>\n      <td>564.000000</td>\n      <td>9.940500e+03</td>\n      <td>17945.500000</td>\n      <td>1736.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.710505e+06</td>\n      <td>871930.000000</td>\n      <td>112719.000000</td>\n      <td>1.907736e+06</td>\n      <td>1.076225e+06</td>\n      <td>39515.000000</td>\n      <td>2.295853e+06</td>\n      <td>956425.000000</td>\n      <td>65970.000000</td>\n      <td>2.216903e+06</td>\n      <td>885333.000000</td>\n      <td>78831.000000</td>\n      <td>2.464364e+06</td>\n      <td>769743.000000</td>\n      <td>200201.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "0-LVluzeSp4P"
   },
   "source": [
    "data = data.to_numpy(dtype=np.int64)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YMNKgPOuSp5D"
   },
   "source": [
    "def plotCounty(state,county,d,r,o,predicted=None):\n",
    "    years = range(2000,2020,4)\n",
    "    plt.figure()\n",
    "    plt.plot(years,d,'b',label='Democrat')\n",
    "    plt.plot(years,r,'r',label='Republican')\n",
    "    plt.plot(years,o,'y',label='Other')\n",
    "    plt.plot(years,d+r+o,'k',label='Total')\n",
    "    if predicted is not None:\n",
    "        new_years = range(2008,2024,4)\n",
    "        plt.plot(new_years,predicted[0]*20000,'c',label='Democrat Model')\n",
    "        plt.plot(new_years,predicted[1]*20000,'m',label='Republican Model')\n",
    "        plt.plot(new_years,predicted[2]*250,'g',label='Other Model')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Votes')\n",
    "    plt.title(county+', '+state)\n",
    "    plt.xticks(years)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "DJh6SpbjSp5s"
   },
   "source": [
    "def calcState(state):\n",
    "    state_df = df[df['state']==state]\n",
    "    state_df = state_df.drop(columns=['state','county'])\n",
    "    state_votes = state_df.values.tolist()\n",
    "    state_votes = np.array(state_votes)\n",
    "    state_votes = np.sum(state_votes,axis=0,dtype=np.int64)\n",
    "    d = []\n",
    "    r = []\n",
    "    o = []\n",
    "    for ind, val in enumerate(state_votes):\n",
    "        party = ind % 3\n",
    "        if party == 0:\n",
    "            d.append(val)\n",
    "        elif party == 1:\n",
    "            r.append(val)\n",
    "        else:\n",
    "            o.append(val)\n",
    "    d = np.array(d)\n",
    "    r = np.array(r)\n",
    "    o = np.array(o)\n",
    "    return d,r,o"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Ir1pXANGSp6F"
   },
   "source": [
    "def plotState(state,d,r,o):\n",
    "    years = range(2000,2020,4)\n",
    "    plt.figure()\n",
    "    plt.plot(years,d,'b',label='Democrat')\n",
    "    plt.plot(years,r,'r',label='Republican')\n",
    "    plt.plot(years,o,'y',label='Other')\n",
    "    plt.plot(years,d+r+o,'k',label='Total')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Votes')\n",
    "    plt.title(state)\n",
    "    plt.xticks(years)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "BhlfhjBISp6o"
   },
   "source": [
    "def convertbyParty(point):\n",
    "    d = point[:,::3]/20000\n",
    "    r = point[:,1::3]/20000\n",
    "    o = point[:,2::3]/250\n",
    "    return d,r,o\n",
    "print(df.loc[0])\n",
    "convertbyParty(np.expand_dims(df.loc[0].values[2:],0))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state          AL\n",
      "county    Autauga\n",
      "2000D        4942\n",
      "2000R       11993\n",
      "2000O         273\n",
      "2004D        4758\n",
      "2004R       15196\n",
      "2004O         127\n",
      "2008D        6093\n",
      "2008R       17403\n",
      "2008O         145\n",
      "2012D        6363\n",
      "2012R       17379\n",
      "2012O         190\n",
      "2016D        5936\n",
      "2016R       18172\n",
      "2016O         865\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0.2471, 0.2379, 0.30465, 0.31815, 0.2968]], dtype=object),\n array([[0.59965, 0.7598, 0.87015, 0.86895, 0.9086]], dtype=object),\n array([[1.092, 0.508, 0.58, 0.76, 3.46]], dtype=object))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sKpS8inlSp7A"
   },
   "source": [
    "def getDataset(data,batch_size,split=True):\n",
    "    data = np.expand_dims(data,axis=-1)\n",
    "    if split:\n",
    "        np.random.shuffle(data)\n",
    "    num = data.shape[0]\n",
    "    train_data = data[:int(num*0.6)]\n",
    "    val_data = data[int(num*0.6):int(num*0.8)]\n",
    "    test_data = data[int(num*0.8):]\n",
    "    def createDS(point,label=True):\n",
    "        d,r,o=convertbyParty(point)\n",
    "        new_data = np.vstack((d,r,o))\n",
    "        if label:\n",
    "            new_data = np.vstack((new_data,new_data*1.5))\n",
    "        ds = tf.data.Dataset.from_tensor_slices(new_data)\n",
    "        if label:\n",
    "            ds = ds.map(lambda p: (p[:-1],p[1:]))\n",
    "        else:\n",
    "            ds = ds.map(lambda p: p[1:])\n",
    "        return ds.batch(batch_size).prefetch(1) if label else ds\n",
    "    if split:\n",
    "        return createDS(train_data),createDS(val_data),createDS(test_data)\n",
    "    else:\n",
    "        return createDS(data,False).batch(100000)"
   ],
   "execution_count": 78,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "FuRS8y-8Sp7O",
    "outputId": "2bffa668-6a35-475d-863b-981d69b4ba82",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "train_ds, val_ds, test_ds = getDataset(data,8)\n",
    "# list(getDataset(data,1,False))[:3]\n"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 4, 1), dtype=float64, numpy=\n array([[[0.25355],\n         [0.2673 ],\n         [0.3604 ],\n         [0.28895]]])>,\n <tf.Tensor: shape=(1, 4, 1), dtype=float64, numpy=\n array([[[0.0241],\n         [0.0204],\n         [0.0218],\n         [0.0162]]])>,\n <tf.Tensor: shape=(1, 4, 1), dtype=float64, numpy=\n array([[[0.14165],\n         [0.14605],\n         [0.1328 ],\n         [0.11325]]])>]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bHcc7PIxSp7h"
   },
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv1D(2,2,activation='relu',input_shape=(4,1)),\n",
    "#     tf.keras.layers.Conv1D(2,2,activation='relu'),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(4,activation='relu'),\n",
    "#     tf.keras.layers.Reshape((4,1)),\n",
    "#     tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(8,return_sequences=True),\n",
    "# ])"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bKa-U7wESp7w"
   },
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(8,2,input_shape=(4,1),activation='relu'),\n",
    "    tf.keras.layers.Conv1D(8,2,activation='relu'),\n",
    "    tf.keras.layers.LSTM(12,return_sequences=True),\n",
    "    tf.keras.layers.LSTM(12,return_sequences=True),\n",
    "    tf.keras.layers.LSTM(12,return_sequences=True),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4),\n",
    "    tf.keras.layers.Reshape((4,1))\n",
    "])"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Sm_qpTzDSp7-",
    "outputId": "ad6aeea9-2d7d-4787-aa25-e7da61f89351",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    }
   },
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss=tf.keras.losses.Huber(),optimizer=optimizer,metrics=['mae','mse'])\n",
    "model.summary()"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 3, 4)              12        \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 3, 8)              416       \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 3, 16)             1600      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 196       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 1)              0         \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SR-cfHLeSp8N"
   },
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"checkpoint4.h5\", save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=125)\n"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lmf1QmWbSp8c",
    "outputId": "bd60f37b-94ab-4e53-f488-2f319d256fa6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# history = model.fit(train_ds,epochs=100,validation_data=val_ds,callbacks=[lr_schedule])\n",
    "# plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "# plt.axis([1e-6, 10, 0, 3])\n",
    "def getlr(epoch):\n",
    "  return 1e-5\n",
    "new_lr = tf.keras.callbacks.LearningRateScheduler(getlr)\n",
    "model.fit(train_ds,epochs=10000,validation_data=val_ds,callbacks=[model_checkpoint,early_stopping,new_lr])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3164 - mae: 0.3858 - mse: 57.9642 - val_loss: 0.1509 - val_mae: 0.2194 - val_mse: 2.5308\n",
      "Epoch 2/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3164 - mae: 0.3850 - mse: 57.9582 - val_loss: 0.1508 - val_mae: 0.2187 - val_mse: 2.5299\n",
      "Epoch 3/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3163 - mae: 0.3848 - mse: 57.9619 - val_loss: 0.1508 - val_mae: 0.2184 - val_mse: 2.5325\n",
      "Epoch 4/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3163 - mae: 0.3847 - mse: 57.9619 - val_loss: 0.1508 - val_mae: 0.2182 - val_mse: 2.5324\n",
      "Epoch 5/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3163 - mae: 0.3846 - mse: 57.9605 - val_loss: 0.1508 - val_mae: 0.2181 - val_mse: 2.5328\n",
      "Epoch 6/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3845 - mse: 57.9582 - val_loss: 0.1508 - val_mae: 0.2180 - val_mse: 2.5327\n",
      "Epoch 7/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3845 - mse: 57.9558 - val_loss: 0.1508 - val_mae: 0.2179 - val_mse: 2.5329\n",
      "Epoch 8/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3845 - mse: 57.9531 - val_loss: 0.1508 - val_mae: 0.2178 - val_mse: 2.5328\n",
      "Epoch 9/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3844 - mse: 57.9504 - val_loss: 0.1508 - val_mae: 0.2178 - val_mse: 2.5330\n",
      "Epoch 10/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3844 - mse: 57.9475 - val_loss: 0.1508 - val_mae: 0.2177 - val_mse: 2.5330\n",
      "Epoch 11/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3844 - mse: 57.9447 - val_loss: 0.1508 - val_mae: 0.2177 - val_mse: 2.5330\n",
      "Epoch 12/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3162 - mae: 0.3843 - mse: 57.9418 - val_loss: 0.1508 - val_mae: 0.2177 - val_mse: 2.5330\n",
      "Epoch 13/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3161 - mae: 0.3843 - mse: 57.9388 - val_loss: 0.1508 - val_mae: 0.2176 - val_mse: 2.5331\n",
      "Epoch 14/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3161 - mae: 0.3843 - mse: 57.9359 - val_loss: 0.1508 - val_mae: 0.2176 - val_mse: 2.5331\n",
      "Epoch 15/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3161 - mae: 0.3843 - mse: 57.9329 - val_loss: 0.1508 - val_mae: 0.2176 - val_mse: 2.5331\n",
      "Epoch 16/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3161 - mae: 0.3842 - mse: 57.9300 - val_loss: 0.1508 - val_mae: 0.2176 - val_mse: 2.5332\n",
      "Epoch 17/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3161 - mae: 0.3842 - mse: 57.9270 - val_loss: 0.1508 - val_mae: 0.2175 - val_mse: 2.5332\n",
      "Epoch 18/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3161 - mae: 0.3842 - mse: 57.9240 - val_loss: 0.1508 - val_mae: 0.2175 - val_mse: 2.5332\n",
      "Epoch 19/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3161 - mae: 0.3842 - mse: 57.9210 - val_loss: 0.1508 - val_mae: 0.2175 - val_mse: 2.5332\n",
      "Epoch 20/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3161 - mae: 0.3842 - mse: 57.9180 - val_loss: 0.1508 - val_mae: 0.2175 - val_mse: 2.5332\n",
      "Epoch 21/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3160 - mae: 0.3841 - mse: 57.9150 - val_loss: 0.1508 - val_mae: 0.2174 - val_mse: 2.5332\n",
      "Epoch 22/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3160 - mae: 0.3841 - mse: 57.9120 - val_loss: 0.1508 - val_mae: 0.2174 - val_mse: 2.5332\n",
      "Epoch 23/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3160 - mae: 0.3841 - mse: 57.9090 - val_loss: 0.1508 - val_mae: 0.2174 - val_mse: 2.5332\n",
      "Epoch 24/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3160 - mae: 0.3841 - mse: 57.9059 - val_loss: 0.1508 - val_mae: 0.2174 - val_mse: 2.5331\n",
      "Epoch 25/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3160 - mae: 0.3841 - mse: 57.9029 - val_loss: 0.1508 - val_mae: 0.2174 - val_mse: 2.5331\n",
      "Epoch 26/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3160 - mae: 0.3840 - mse: 57.8999 - val_loss: 0.1508 - val_mae: 0.2174 - val_mse: 2.5331\n",
      "Epoch 27/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3160 - mae: 0.3840 - mse: 57.8968 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5331\n",
      "Epoch 28/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3840 - mse: 57.8938 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5331\n",
      "Epoch 29/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3159 - mae: 0.3840 - mse: 57.8907 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5330\n",
      "Epoch 30/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3840 - mse: 57.8877 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5330\n",
      "Epoch 31/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3839 - mse: 57.8847 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5330\n",
      "Epoch 32/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3839 - mse: 57.8816 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5330\n",
      "Epoch 33/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3839 - mse: 57.8786 - val_loss: 0.1508 - val_mae: 0.2173 - val_mse: 2.5329\n",
      "Epoch 34/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3839 - mse: 57.8756 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5329\n",
      "Epoch 35/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3159 - mae: 0.3839 - mse: 57.8725 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5329\n",
      "Epoch 36/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3158 - mae: 0.3839 - mse: 57.8695 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5329\n",
      "Epoch 37/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3158 - mae: 0.3838 - mse: 57.8664 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5328\n",
      "Epoch 38/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3158 - mae: 0.3838 - mse: 57.8634 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5328\n",
      "Epoch 39/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3158 - mae: 0.3838 - mse: 57.8603 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5328\n",
      "Epoch 40/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3158 - mae: 0.3838 - mse: 57.8573 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5328\n",
      "Epoch 41/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3158 - mae: 0.3838 - mse: 57.8543 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5327\n",
      "Epoch 42/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3158 - mae: 0.3838 - mse: 57.8513 - val_loss: 0.1508 - val_mae: 0.2172 - val_mse: 2.5327\n",
      "Epoch 43/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3158 - mae: 0.3837 - mse: 57.8482 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5327\n",
      "Epoch 44/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3157 - mae: 0.3837 - mse: 57.8452 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5327\n",
      "Epoch 45/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3157 - mae: 0.3837 - mse: 57.8421 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5326\n",
      "Epoch 46/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3157 - mae: 0.3837 - mse: 57.8391 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5326\n",
      "Epoch 47/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3157 - mae: 0.3837 - mse: 57.8361 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5326\n",
      "Epoch 48/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3157 - mae: 0.3837 - mse: 57.8330 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5326\n",
      "Epoch 49/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3157 - mae: 0.3836 - mse: 57.8300 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5325\n",
      "Epoch 50/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3157 - mae: 0.3836 - mse: 57.8270 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5325\n",
      "Epoch 51/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3157 - mae: 0.3836 - mse: 57.8240 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5325\n",
      "Epoch 52/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3156 - mae: 0.3836 - mse: 57.8209 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5324\n",
      "Epoch 53/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3156 - mae: 0.3836 - mse: 57.8179 - val_loss: 0.1508 - val_mae: 0.2171 - val_mse: 2.5324\n",
      "Epoch 54/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3156 - mae: 0.3836 - mse: 57.8148 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5324\n",
      "Epoch 55/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3156 - mae: 0.3835 - mse: 57.8119 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5324\n",
      "Epoch 56/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3156 - mae: 0.3835 - mse: 57.8089 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5324\n",
      "Epoch 57/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3156 - mae: 0.3835 - mse: 57.8059 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5323\n",
      "Epoch 58/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3156 - mae: 0.3835 - mse: 57.8029 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5323\n",
      "Epoch 59/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3156 - mae: 0.3835 - mse: 57.7999 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5323\n",
      "Epoch 60/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3155 - mae: 0.3835 - mse: 57.7969 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5323\n",
      "Epoch 61/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7939 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5322\n",
      "Epoch 62/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7909 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5322\n",
      "Epoch 63/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7879 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5322\n",
      "Epoch 64/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7849 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5322\n",
      "Epoch 65/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7819 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5321\n",
      "Epoch 66/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7790 - val_loss: 0.1508 - val_mae: 0.2170 - val_mse: 2.5321\n",
      "Epoch 67/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3155 - mae: 0.3834 - mse: 57.7760 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5321\n",
      "Epoch 68/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3833 - mse: 57.7730 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5321\n",
      "Epoch 69/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3833 - mse: 57.7701 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5320\n",
      "Epoch 70/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3833 - mse: 57.7671 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5320\n",
      "Epoch 71/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3833 - mse: 57.7641 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5320\n",
      "Epoch 72/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3833 - mse: 57.7611 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5320\n",
      "Epoch 73/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3833 - mse: 57.7581 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5319\n",
      "Epoch 74/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3154 - mae: 0.3832 - mse: 57.7552 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5319\n",
      "Epoch 75/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3154 - mae: 0.3832 - mse: 57.7522 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5319\n",
      "Epoch 76/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3153 - mae: 0.3832 - mse: 57.7492 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5319\n",
      "Epoch 77/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3153 - mae: 0.3832 - mse: 57.7463 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5319\n",
      "Epoch 78/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3153 - mae: 0.3832 - mse: 57.7433 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5318\n",
      "Epoch 79/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3153 - mae: 0.3832 - mse: 57.7403 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5318\n",
      "Epoch 80/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3153 - mae: 0.3832 - mse: 57.7374 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5318\n",
      "Epoch 81/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3153 - mae: 0.3831 - mse: 57.7344 - val_loss: 0.1508 - val_mae: 0.2169 - val_mse: 2.5318\n",
      "Epoch 82/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3153 - mae: 0.3831 - mse: 57.7314 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5318\n",
      "Epoch 83/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3153 - mae: 0.3831 - mse: 57.7285 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5317\n",
      "Epoch 84/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3152 - mae: 0.3831 - mse: 57.7255 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5317\n",
      "Epoch 85/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3152 - mae: 0.3831 - mse: 57.7226 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5317\n",
      "Epoch 86/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3152 - mae: 0.3831 - mse: 57.7196 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5317\n",
      "Epoch 87/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3152 - mae: 0.3831 - mse: 57.7166 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5317\n",
      "Epoch 88/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3152 - mae: 0.3830 - mse: 57.7137 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5316\n",
      "Epoch 89/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3152 - mae: 0.3830 - mse: 57.7107 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5316\n",
      "Epoch 90/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3152 - mae: 0.3830 - mse: 57.7077 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5316\n",
      "Epoch 91/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3152 - mae: 0.3830 - mse: 57.7048 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5316\n",
      "Epoch 92/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3151 - mae: 0.3830 - mse: 57.7018 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5315\n",
      "Epoch 93/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3830 - mse: 57.6989 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5315\n",
      "Epoch 94/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3830 - mse: 57.6959 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5315\n",
      "Epoch 95/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3829 - mse: 57.6930 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5315\n",
      "Epoch 96/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3829 - mse: 57.6900 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5315\n",
      "Epoch 97/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3829 - mse: 57.6871 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5314\n",
      "Epoch 98/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3829 - mse: 57.6841 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5314\n",
      "Epoch 99/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3151 - mae: 0.3829 - mse: 57.6812 - val_loss: 0.1508 - val_mae: 0.2168 - val_mse: 2.5314\n",
      "Epoch 100/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3150 - mae: 0.3829 - mse: 57.6782 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5314\n",
      "Epoch 101/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6752 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5314\n",
      "Epoch 102/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6723 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5313\n",
      "Epoch 103/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6693 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5313\n",
      "Epoch 104/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6664 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5313\n",
      "Epoch 105/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6634 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5313\n",
      "Epoch 106/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6605 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5312\n",
      "Epoch 107/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3150 - mae: 0.3828 - mse: 57.6575 - val_loss: 0.1508 - val_mae: 0.2167 - val_mse: 2.5312\n",
      "Epoch 108/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6546 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5312\n",
      "Epoch 109/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6516 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5312\n",
      "Epoch 110/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6487 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5311\n",
      "Epoch 111/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6457 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5311\n",
      "Epoch 112/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6428 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5311\n",
      "Epoch 113/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6398 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5311\n",
      "Epoch 114/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3827 - mse: 57.6369 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5310\n",
      "Epoch 115/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3826 - mse: 57.6339 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5310\n",
      "Epoch 116/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3149 - mae: 0.3826 - mse: 57.6310 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5310\n",
      "Epoch 117/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3826 - mse: 57.6280 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5310\n",
      "Epoch 118/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3826 - mse: 57.6251 - val_loss: 0.1507 - val_mae: 0.2167 - val_mse: 2.5309\n",
      "Epoch 119/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3148 - mae: 0.3826 - mse: 57.6221 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5309\n",
      "Epoch 120/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3826 - mse: 57.6192 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5309\n",
      "Epoch 121/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3826 - mse: 57.6162 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5309\n",
      "Epoch 122/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3825 - mse: 57.6133 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5308\n",
      "Epoch 123/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3825 - mse: 57.6103 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5308\n",
      "Epoch 124/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3148 - mae: 0.3825 - mse: 57.6074 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5308\n",
      "Epoch 125/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3147 - mae: 0.3825 - mse: 57.6044 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5308\n",
      "Epoch 126/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3147 - mae: 0.3825 - mse: 57.6015 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5307\n",
      "Epoch 127/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3147 - mae: 0.3825 - mse: 57.5985 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5307\n",
      "Epoch 128/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3147 - mae: 0.3825 - mse: 57.5956 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5307\n",
      "Epoch 129/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3147 - mae: 0.3824 - mse: 57.5926 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5307\n",
      "Epoch 130/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3147 - mae: 0.3824 - mse: 57.5897 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5306\n",
      "Epoch 131/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3147 - mae: 0.3824 - mse: 57.5868 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5306\n",
      "Epoch 132/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3147 - mae: 0.3824 - mse: 57.5838 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5306\n",
      "Epoch 133/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3824 - mse: 57.5809 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5306\n",
      "Epoch 134/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3824 - mse: 57.5779 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5305\n",
      "Epoch 135/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3824 - mse: 57.5750 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5305\n",
      "Epoch 136/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3823 - mse: 57.5720 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5305\n",
      "Epoch 137/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3823 - mse: 57.5691 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5305\n",
      "Epoch 138/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3823 - mse: 57.5661 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5304\n",
      "Epoch 139/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3823 - mse: 57.5632 - val_loss: 0.1507 - val_mae: 0.2166 - val_mse: 2.5304\n",
      "Epoch 140/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3146 - mae: 0.3823 - mse: 57.5602 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5304\n",
      "Epoch 141/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3823 - mse: 57.5573 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5304\n",
      "Epoch 142/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3823 - mse: 57.5544 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5303\n",
      "Epoch 143/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5514 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5303\n",
      "Epoch 144/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5485 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5303\n",
      "Epoch 145/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5455 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5302\n",
      "Epoch 146/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5426 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5302\n",
      "Epoch 147/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5397 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5302\n",
      "Epoch 148/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5367 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5302\n",
      "Epoch 149/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3145 - mae: 0.3822 - mse: 57.5338 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5301\n",
      "Epoch 150/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5308 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5301\n",
      "Epoch 151/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5279 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5301\n",
      "Epoch 152/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5249 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5300\n",
      "Epoch 153/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5220 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5300\n",
      "Epoch 154/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5190 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5300\n",
      "Epoch 155/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5161 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5300\n",
      "Epoch 156/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3821 - mse: 57.5132 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5299\n",
      "Epoch 157/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3144 - mae: 0.3820 - mse: 57.5102 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5299\n",
      "Epoch 158/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3820 - mse: 57.5073 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5299\n",
      "Epoch 159/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3820 - mse: 57.5043 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5298\n",
      "Epoch 160/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3820 - mse: 57.5014 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5298\n",
      "Epoch 161/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3820 - mse: 57.4984 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5298\n",
      "Epoch 162/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3820 - mse: 57.4955 - val_loss: 0.1507 - val_mae: 0.2165 - val_mse: 2.5298\n",
      "Epoch 163/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3820 - mse: 57.4926 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5297\n",
      "Epoch 164/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3819 - mse: 57.4897 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5297\n",
      "Epoch 165/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3143 - mae: 0.3819 - mse: 57.4867 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5297\n",
      "Epoch 166/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3819 - mse: 57.4838 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5296\n",
      "Epoch 167/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3819 - mse: 57.4808 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5296\n",
      "Epoch 168/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3819 - mse: 57.4779 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5296\n",
      "Epoch 169/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3819 - mse: 57.4750 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5295\n",
      "Epoch 170/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3819 - mse: 57.4720 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5295\n",
      "Epoch 171/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3818 - mse: 57.4691 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5295\n",
      "Epoch 172/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3818 - mse: 57.4661 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5295\n",
      "Epoch 173/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3818 - mse: 57.4632 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5294\n",
      "Epoch 174/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3142 - mae: 0.3818 - mse: 57.4603 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5294\n",
      "Epoch 175/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3818 - mse: 57.4573 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5294\n",
      "Epoch 176/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3818 - mse: 57.4544 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5293\n",
      "Epoch 177/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3818 - mse: 57.4515 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5293\n",
      "Epoch 178/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3818 - mse: 57.4485 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5293\n",
      "Epoch 179/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3817 - mse: 57.4456 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5292\n",
      "Epoch 180/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3817 - mse: 57.4426 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5292\n",
      "Epoch 181/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3817 - mse: 57.4397 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5292\n",
      "Epoch 182/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3141 - mae: 0.3817 - mse: 57.4367 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5292\n",
      "Epoch 183/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3817 - mse: 57.4338 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5291\n",
      "Epoch 184/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3817 - mse: 57.4308 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5291\n",
      "Epoch 185/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3817 - mse: 57.4279 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5291\n",
      "Epoch 186/10000\n",
      "1294/1294 [==============================] - 7s 6ms/step - loss: 0.3140 - mae: 0.3816 - mse: 57.4249 - val_loss: 0.1507 - val_mae: 0.2164 - val_mse: 2.5290\n",
      "Epoch 187/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3816 - mse: 57.4220 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5290\n",
      "Epoch 188/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3816 - mse: 57.4190 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5290\n",
      "Epoch 189/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3816 - mse: 57.4161 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5289\n",
      "Epoch 190/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3140 - mae: 0.3816 - mse: 57.4131 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5289\n",
      "Epoch 191/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3816 - mse: 57.4102 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5289\n",
      "Epoch 192/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3816 - mse: 57.4072 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5288\n",
      "Epoch 193/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3815 - mse: 57.4043 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5288\n",
      "Epoch 194/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3815 - mse: 57.4013 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5288\n",
      "Epoch 195/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3815 - mse: 57.3984 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5288\n",
      "Epoch 196/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3815 - mse: 57.3955 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5287\n",
      "Epoch 197/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3815 - mse: 57.3925 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5287\n",
      "Epoch 198/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3139 - mae: 0.3815 - mse: 57.3895 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5287\n",
      "Epoch 199/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3815 - mse: 57.3866 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5286\n",
      "Epoch 200/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3837 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5286\n",
      "Epoch 201/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3807 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5286\n",
      "Epoch 202/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3778 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5285\n",
      "Epoch 203/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3748 - val_loss: 0.1507 - val_mae: 0.2163 - val_mse: 2.5285\n",
      "Epoch 204/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3719 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5285\n",
      "Epoch 205/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3689 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5285\n",
      "Epoch 206/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3814 - mse: 57.3660 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5284\n",
      "Epoch 207/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3138 - mae: 0.3813 - mse: 57.3630 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5284\n",
      "Epoch 208/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3813 - mse: 57.3601 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5284\n",
      "Epoch 209/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3813 - mse: 57.3571 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5283\n",
      "Epoch 210/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3813 - mse: 57.3542 - val_loss: 0.1506 - val_mae: 0.2163 - val_mse: 2.5283\n",
      "Epoch 211/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3813 - mse: 57.3513 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5283\n",
      "Epoch 212/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3813 - mse: 57.3483 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5282\n",
      "Epoch 213/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3813 - mse: 57.3453 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5282\n",
      "Epoch 214/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3812 - mse: 57.3424 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5282\n",
      "Epoch 215/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3137 - mae: 0.3812 - mse: 57.3394 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5281\n",
      "Epoch 216/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3812 - mse: 57.3365 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5281\n",
      "Epoch 217/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3812 - mse: 57.3335 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5281\n",
      "Epoch 218/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3812 - mse: 57.3306 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5280\n",
      "Epoch 219/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3812 - mse: 57.3276 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5280\n",
      "Epoch 220/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3812 - mse: 57.3247 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5280\n",
      "Epoch 221/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3812 - mse: 57.3217 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5279\n",
      "Epoch 222/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3811 - mse: 57.3188 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5279\n",
      "Epoch 223/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3811 - mse: 57.3158 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5279\n",
      "Epoch 224/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3136 - mae: 0.3811 - mse: 57.3129 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5278\n",
      "Epoch 225/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3811 - mse: 57.3099 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5278\n",
      "Epoch 226/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3811 - mse: 57.3070 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5278\n",
      "Epoch 227/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3811 - mse: 57.3040 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5278\n",
      "Epoch 228/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3811 - mse: 57.3011 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5277\n",
      "Epoch 229/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3810 - mse: 57.2981 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5277\n",
      "Epoch 230/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3810 - mse: 57.2952 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5277\n",
      "Epoch 231/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3810 - mse: 57.2922 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5276\n",
      "Epoch 232/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3135 - mae: 0.3810 - mse: 57.2893 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5276\n",
      "Epoch 233/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3810 - mse: 57.2863 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5276\n",
      "Epoch 234/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3810 - mse: 57.2834 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5275\n",
      "Epoch 235/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3810 - mse: 57.2804 - val_loss: 0.1506 - val_mae: 0.2162 - val_mse: 2.5275\n",
      "Epoch 236/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3809 - mse: 57.2775 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5275\n",
      "Epoch 237/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3809 - mse: 57.2745 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5274\n",
      "Epoch 238/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3809 - mse: 57.2716 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5274\n",
      "Epoch 239/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3809 - mse: 57.2687 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5274\n",
      "Epoch 240/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3134 - mae: 0.3809 - mse: 57.2657 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5273\n",
      "Epoch 241/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3809 - mse: 57.2628 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5273\n",
      "Epoch 242/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3809 - mse: 57.2598 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5273\n",
      "Epoch 243/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2569 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5272\n",
      "Epoch 244/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2539 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5272\n",
      "Epoch 245/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2510 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5272\n",
      "Epoch 246/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2481 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5271\n",
      "Epoch 247/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2451 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5271\n",
      "Epoch 248/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2422 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5271\n",
      "Epoch 249/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3133 - mae: 0.3808 - mse: 57.2392 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5271\n",
      "Epoch 250/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3808 - mse: 57.2363 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5270\n",
      "Epoch 251/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2334 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5270\n",
      "Epoch 252/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2304 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5270\n",
      "Epoch 253/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2275 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5269\n",
      "Epoch 254/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2246 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5269\n",
      "Epoch 255/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2217 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5269\n",
      "Epoch 256/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2188 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5269\n",
      "Epoch 257/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3132 - mae: 0.3807 - mse: 57.2159 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5268\n",
      "Epoch 258/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.2130 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5268\n",
      "Epoch 259/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.2101 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5268\n",
      "Epoch 260/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.2072 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5267\n",
      "Epoch 261/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.2043 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5267\n",
      "Epoch 262/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.2014 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5267\n",
      "Epoch 263/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.1985 - val_loss: 0.1506 - val_mae: 0.2161 - val_mse: 2.5267\n",
      "Epoch 264/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3806 - mse: 57.1956 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5266\n",
      "Epoch 265/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3805 - mse: 57.1927 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5266\n",
      "Epoch 266/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3131 - mae: 0.3805 - mse: 57.1898 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5266\n",
      "Epoch 267/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3805 - mse: 57.1869 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5265\n",
      "Epoch 268/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3805 - mse: 57.1841 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5265\n",
      "Epoch 269/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3805 - mse: 57.1812 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5265\n",
      "Epoch 270/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3805 - mse: 57.1783 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5264\n",
      "Epoch 271/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3805 - mse: 57.1755 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5264\n",
      "Epoch 272/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3805 - mse: 57.1726 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5264\n",
      "Epoch 273/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3804 - mse: 57.1697 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5264\n",
      "Epoch 274/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3804 - mse: 57.1668 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5263\n",
      "Epoch 275/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3130 - mae: 0.3804 - mse: 57.1640 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5263\n",
      "Epoch 276/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3804 - mse: 57.1611 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5263\n",
      "Epoch 277/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3804 - mse: 57.1582 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5262\n",
      "Epoch 278/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3804 - mse: 57.1554 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5262\n",
      "Epoch 279/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3804 - mse: 57.1525 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5262\n",
      "Epoch 280/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3803 - mse: 57.1497 - val_loss: 0.1506 - val_mae: 0.2160 - val_mse: 2.5262\n",
      "Epoch 281/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3803 - mse: 57.1468 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5261\n",
      "Epoch 282/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3803 - mse: 57.1439 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5261\n",
      "Epoch 283/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3129 - mae: 0.3803 - mse: 57.1411 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5261\n",
      "Epoch 284/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3803 - mse: 57.1383 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5261\n",
      "Epoch 285/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3803 - mse: 57.1354 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5260\n",
      "Epoch 286/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3803 - mse: 57.1326 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5260\n",
      "Epoch 287/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3803 - mse: 57.1297 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5260\n",
      "Epoch 288/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3802 - mse: 57.1269 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5260\n",
      "Epoch 289/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3802 - mse: 57.1241 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5259\n",
      "Epoch 290/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3802 - mse: 57.1212 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5259\n",
      "Epoch 291/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3802 - mse: 57.1184 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5259\n",
      "Epoch 292/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3128 - mae: 0.3802 - mse: 57.1156 - val_loss: 0.1505 - val_mae: 0.2160 - val_mse: 2.5259\n",
      "Epoch 293/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3802 - mse: 57.1127 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5258\n",
      "Epoch 294/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3802 - mse: 57.1099 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5258\n",
      "Epoch 295/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.1071 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5258\n",
      "Epoch 296/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.1043 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5257\n",
      "Epoch 297/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.1014 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5257\n",
      "Epoch 298/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.0986 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5257\n",
      "Epoch 299/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.0958 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5257\n",
      "Epoch 300/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.0930 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5256\n",
      "Epoch 301/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3127 - mae: 0.3801 - mse: 57.0902 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5256\n",
      "Epoch 302/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3801 - mse: 57.0873 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5256\n",
      "Epoch 303/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0845 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5256\n",
      "Epoch 304/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0817 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5255\n",
      "Epoch 305/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0789 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5255\n",
      "Epoch 306/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0761 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5255\n",
      "Epoch 307/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0733 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5255\n",
      "Epoch 308/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0705 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5254\n",
      "Epoch 309/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3126 - mae: 0.3800 - mse: 57.0677 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5254\n",
      "Epoch 310/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0649 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5254\n",
      "Epoch 311/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0621 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5254\n",
      "Epoch 312/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0593 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5253\n",
      "Epoch 313/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0565 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5253\n",
      "Epoch 314/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0537 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5253\n",
      "Epoch 315/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0509 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5253\n",
      "Epoch 316/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0481 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5252\n",
      "Epoch 317/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3799 - mse: 57.0453 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5252\n",
      "Epoch 318/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3125 - mae: 0.3798 - mse: 57.0425 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5252\n",
      "Epoch 319/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3798 - mse: 57.0398 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5252\n",
      "Epoch 320/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3798 - mse: 57.0370 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5251\n",
      "Epoch 321/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3798 - mse: 57.0342 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5251\n",
      "Epoch 322/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3798 - mse: 57.0314 - val_loss: 0.1505 - val_mae: 0.2159 - val_mse: 2.5251\n",
      "Epoch 323/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3798 - mse: 57.0286 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5251\n",
      "Epoch 324/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3798 - mse: 57.0259 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5250\n",
      "Epoch 325/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3797 - mse: 57.0231 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5250\n",
      "Epoch 326/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3797 - mse: 57.0203 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5250\n",
      "Epoch 327/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3124 - mae: 0.3797 - mse: 57.0175 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5250\n",
      "Epoch 328/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3797 - mse: 57.0147 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5249\n",
      "Epoch 329/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3797 - mse: 57.0120 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5249\n",
      "Epoch 330/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3797 - mse: 57.0092 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5249\n",
      "Epoch 331/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3797 - mse: 57.0064 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5249\n",
      "Epoch 332/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3797 - mse: 57.0037 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5248\n",
      "Epoch 333/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3796 - mse: 57.0009 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5248\n",
      "Epoch 334/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3796 - mse: 56.9981 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5248\n",
      "Epoch 335/10000\n",
      "1294/1294 [==============================] - 8s 7ms/step - loss: 0.3123 - mae: 0.3796 - mse: 56.9953 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5248\n",
      "Epoch 336/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3123 - mae: 0.3796 - mse: 56.9925 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5247\n",
      "Epoch 337/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3796 - mse: 56.9898 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5247\n",
      "Epoch 338/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3796 - mse: 56.9870 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5247\n",
      "Epoch 339/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3796 - mse: 56.9842 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5247\n",
      "Epoch 340/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3796 - mse: 56.9814 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5246\n",
      "Epoch 341/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3795 - mse: 56.9787 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5246\n",
      "Epoch 342/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3795 - mse: 56.9759 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5246\n",
      "Epoch 343/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3795 - mse: 56.9732 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5246\n",
      "Epoch 344/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3122 - mae: 0.3795 - mse: 56.9704 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5246\n",
      "Epoch 345/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3795 - mse: 56.9676 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5245\n",
      "Epoch 346/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3795 - mse: 56.9649 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5245\n",
      "Epoch 347/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3795 - mse: 56.9621 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5245\n",
      "Epoch 348/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3794 - mse: 56.9593 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5245\n",
      "Epoch 349/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3794 - mse: 56.9566 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5244\n",
      "Epoch 350/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3794 - mse: 56.9538 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5244\n",
      "Epoch 351/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3794 - mse: 56.9511 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5244\n",
      "Epoch 352/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3794 - mse: 56.9483 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5244\n",
      "Epoch 353/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3121 - mae: 0.3794 - mse: 56.9456 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5244\n",
      "Epoch 354/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3794 - mse: 56.9428 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5243\n",
      "Epoch 355/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3794 - mse: 56.9401 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5243\n",
      "Epoch 356/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9373 - val_loss: 0.1505 - val_mae: 0.2158 - val_mse: 2.5243\n",
      "Epoch 357/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9346 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5243\n",
      "Epoch 358/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9318 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5242\n",
      "Epoch 359/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9291 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5242\n",
      "Epoch 360/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9263 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5242\n",
      "Epoch 361/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9236 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5242\n",
      "Epoch 362/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3120 - mae: 0.3793 - mse: 56.9208 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5242\n",
      "Epoch 363/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3119 - mae: 0.3793 - mse: 56.9181 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5241\n",
      "Epoch 364/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3119 - mae: 0.3792 - mse: 56.9153 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5241\n",
      "Epoch 365/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3119 - mae: 0.3792 - mse: 56.9126 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5241\n",
      "Epoch 366/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3119 - mae: 0.3792 - mse: 56.9099 - val_loss: 0.1505 - val_mae: 0.2157 - val_mse: 2.5241\n",
      "Epoch 367/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3119 - mae: 0.3792 - mse: 56.9071 - val_loss: 0.1504 - val_mae: 0.2157 - val_mse: 2.5241\n",
      "Epoch 368/10000\n",
      "1294/1294 [==============================] - 8s 6ms/step - loss: 0.3119 - mae: 0.3792 - mse: 56.9044 - val_loss: 0.1504 - val_mae: 0.2157 - val_mse: 2.5240\n",
      "Epoch 369/10000\n",
      " 644/1294 [=============>................] - ETA: 3s - loss: 0.2215 - mae: 0.2813 - mse: 26.5140"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sY9EgNpOSp8s"
   },
   "source": [
    "c = 'Racine'\n",
    "s = 'WI'\n",
    "r = df[(df['state']==s)&(df['county']==c)]"
   ],
   "execution_count": 138,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lCSQPQbsSp87"
   },
   "source": [
    "model4 = tf.keras.models.load_model('checkpoint2.h5')\n",
    "row = r.drop(columns=['state','county'])\n",
    "row = row.to_numpy()\n",
    "dataset = getDataset(row,8,False)"
   ],
   "execution_count": 139,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "IKZQWaW-Sp9N",
    "outputId": "a201a597-bade-49d6-fd9b-230df224ce05",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "results = model4.predict(dataset)"
   ],
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000151F860B730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "J-2cK6uCSp9k",
    "outputId": "73307db3-2e1e-4dd5-ff6a-62ae54c0caa9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    }
   },
   "source": [
    "dem = np.array(r.values.tolist()[0][2::3])\n",
    "gop = np.array(r.values.tolist()[0][3::3])\n",
    "other = np.array(r.values.tolist()[0][4::3])\n",
    "plotCounty(s,c,dem,gop,other,results)"
   ],
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  }
 ]
}